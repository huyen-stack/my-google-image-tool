import streamlit as st
import google.generativeai as genai
import tempfile
import os
import cv2
import numpy as np
from PIL import Image
import concurrent.futures
import json
from datetime import datetime
import yt_dlp
from typing import Optional, Tuple, List, Dict, Any

# ========================
# å…¨å±€é…ç½®
# ========================

GEMINI_MODEL_NAME = "gemini-flash-latest"
FREE_TIER_RPM_LIMIT = 10  # å…è´¹ç‰ˆå…¸å‹ï¼š1 åˆ†é’Ÿ 10 æ¬¡ generateContent

if "api_key" not in st.session_state:
    st.session_state["api_key"] = ""
if "analysis_history" not in st.session_state:
    st.session_state["analysis_history"] = []


# ========================
# é¡µé¢æ ·å¼
# ========================

st.set_page_config(
    page_title="AI å¤šå®ä½“è¿åŠ¨ & ç©ºä¸­é•œå¤´åˆ†æåŠ©æ‰‹",
    page_icon="ğŸ¬",
    layout="wide",
)

st.markdown(
    """
    <style>
    .main {
        background-color: #020617;
        color: #e5e7eb;
    }
    .stMarkdown, .stText {
        color: #e5e7eb;
    }
    .stCode {
        font-size: 0.9rem !important;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

st.markdown(
    """
    <div style="
        padding: 18px 24px;
        border-radius: 18px;
        margin-bottom: 16px;
        background: radial-gradient(circle at top left, #3b82f6 0, #020617 55%, #020617 100%);
        border: 1px solid rgba(148, 163, 184, 0.35);
    ">
      <h1 style="margin: 0 0 8px 0; color: #e5e7eb; font-size: 1.6rem;">
        ğŸ¬ AI å¤šå®ä½“è¿åŠ¨ & ç©ºä¸­é•œå¤´åˆ†æåŠ©æ‰‹
      </h1>
      <p style="margin: 0; color: #cbd5f5; font-size: 0.96rem;">
        ä¸Šä¼ è§†é¢‘æˆ–è¾“å…¥æŠ–éŸ³ / Bç«™ / TikTok / YouTube é“¾æ¥ï¼Œè‡ªåŠ¨æŠ½å–å…³é”®å¸§ï¼Œ
        åˆ†æç”»é¢ä¸­<b>äººç‰©ã€è½¦è¾†ã€è¿åŠ¨ç‰©ä½“</b>çš„åŠ¨ä½œå…³ç³»ï¼Œ
        å¹¶å¯é’ˆå¯¹<b>æ— äººæœº / ç©¿è¶Šæœº / è¶…äººèµ·é£ / é«˜æ¥¼è·³ä¸‹</b>é•œå¤´åšä¸“ä¸šé£è¡Œè½¨è¿¹ + è¿é•œæ€»ç»“ï¼Œ
        åŒæ—¶ç”Ÿæˆé€‚åˆ SORA / Veo çš„è‹±æ–‡æç¤ºè¯ã€‚
      </p>
    </div>
    """,
    unsafe_allow_html=True,
)


# ========================
# å·¥å…·å‡½æ•°ï¼šæŠ½å¸§ & ä¸‹è½½
# ========================

def extract_keyframes_dynamic(
    video_path: str,
    min_frames: int = 6,
    max_frames: int = 20,
    base_fps: float = 0.8,
    start_sec: Optional[float] = None,
    end_sec: Optional[float] = None,
) -> Tuple[List[Image.Image], float, Tuple[float, float]]:
    """
    æ ¹æ®è§†é¢‘æ—¶é•¿ï¼Œåœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…å‡åŒ€æŠ½å¸§ã€‚
    è¿”å›ï¼š
      images: PIL.Image åˆ—è¡¨
      duration: æ•´æ¡è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
      used_range: (start_used, end_used)
    """
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps is None or fps <= 1e-2:
        fps = 25.0

    if total_frames <= 0:
        cap.release()
        return [], 0.0, (0.0, 0.0)

    duration = total_frames / fps

    # è§„èŒƒæ—¶é—´èŒƒå›´
    if start_sec is None or start_sec < 0:
        start_sec = 0.0
    if end_sec is None or end_sec <= start_sec or end_sec > duration:
        end_sec = duration

    start_frame = int(start_sec * fps)
    end_frame_excl = min(total_frames, int(end_sec * fps))
    segment_frames = end_frame_excl - start_frame

    # å¦‚æœåŒºé—´éæ³•ï¼Œé€€å›æ•´æ®µ
    if segment_frames <= 0:
        start_sec = 0.0
        end_sec = duration
        start_frame = 0
        end_frame_excl = total_frames
        segment_frames = total_frames

    segment_duration = segment_frames / fps

    ideal_n = int(segment_duration * base_fps)
    target_n = max(min_frames, ideal_n)
    target_n = min(target_n, max_frames, segment_frames)

    if target_n <= 0:
        cap.release()
        return [], duration, (start_sec, end_sec)

    step = segment_frames / float(target_n)
    frame_indices = [start_frame + int(i * step) for i in range(target_n)]

    images: List[Image.Image] = []
    for idx in frame_indices:
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if ret and frame is not None:
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            images.append(Image.fromarray(rgb_frame))
        else:
            images.append(Image.new("RGB", (200, 200), color="gray"))

    cap.release()
    return images, duration, (start_sec, end_sec)


def download_video_from_url(url: str) -> str:
    """ç”¨ yt-dlp ä¸‹è½½è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶ï¼Œè¿”å›è·¯å¾„ã€‚"""
    if not url:
        raise ValueError("è§†é¢‘é“¾æ¥ä¸ºç©º")

    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    tmp_path = tmp.name
    tmp.close()

    ydl_opts = {
        "format": "mp4/bestvideo+bestaudio/best",
        "outtmpl": tmp_path,
        "merge_output_format": "mp4",
        "quiet": True,
        "no_warnings": True,
    }

    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        ydl.download([url])

    return tmp_path


def _extract_text_from_response(resp) -> str:
    """å…¼å®¹ä¸åŒ Gemini è¿”å›ç»“æ„ï¼Œå°½é‡æ‹¿åˆ°çº¯æ–‡æœ¬ã€‚"""
    text = getattr(resp, "text", None)
    if text and isinstance(text, str) and text.strip():
        return text.strip()

    try:
        texts = []
        for cand in getattr(resp, "candidates", []) or []:
            content = getattr(cand, "content", None)
            if not content:
                continue
            for part in getattr(content, "parts", []) or []:
                part_text = getattr(part, "text", None)
                if part_text:
                    texts.append(part_text)
        if texts:
            return " ".join(texts).strip()
    except Exception:
        pass

    try:
        return str(resp)
    except Exception:
        return ""


# ========================
# å•å¸§ï¼šå¤šå®ä½“è¿åŠ¨åˆ†æ
# ========================

def analyze_motion_single_frame(
    img: Image.Image,
    model,
    index: int,
) -> Dict[str, Any]:
    """
    å•å¸§åˆ†æï¼š
    - moving_entitiesï¼šåŒ…æ‹¬äººç‰© / è½¦è¾† / å…¶ä»–æ˜æ˜¾è¿åŠ¨ç‰©ä½“
    - æ¯ä¸ªå®ä½“çš„åŠ¨ä½œç®€è¿°ã€è§’è‰²ã€æ–¹å‘ã€é€Ÿåº¦
    - é•œå¤´è¿åŠ¨ + å¤šå®ä½“äº’åŠ¨ + åŠ¨ä½œè¶‹åŠ¿
    """
    try:
        prompt = f"""
ä½ ç°åœ¨æ˜¯â€œåŠ¨ä½œè®¾è®¡æ€»ç›‘ + ç”µå½±å¯¼æ¼” + ç‰¹æŠ€åè°ƒ + æ±½è½¦ç‰¹æŠ€æŒ‡å¯¼â€ã€‚
åªä¸“æ³¨ç”»é¢ä¸­æ‰€æœ‰â€œåœ¨è¿åŠ¨çš„ä¸œè¥¿â€ï¼šäººç‰©ã€æ±½è½¦ã€æ‘©æ‰˜è½¦ã€è‡ªè¡Œè½¦ã€çƒã€é£è¡Œå™¨ã€æŠ›æ·ç‰©ç­‰ã€‚

è¯·å¯¹ç»™ä½ çš„è¿™ä¸€å¸§ç”»é¢è¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ï¼š

{{
  "index": {index},

  "scene_motion_brief_zh": "ç”¨ 1 å¥ä¸­æ–‡æ¦‚æ‹¬æœ¬å¸§é˜¶æ®µçš„æ•´ä½“è¿åŠ¨ï¼ˆä¾‹å¦‚ï¼šå¥³ä¸»åœ¨å±‹é¡¶å¥”è·‘çš„åŒæ—¶ï¼Œçº¢è‰²è·‘è½¦ä»ä¸‹æ–¹è¡—é“é«˜é€Ÿæ è¿‡ï¼‰",

  "moving_entities": [
    {{
      "id": "E1",
      "type": "person / car / motorbike / bicycle / object / animal / other",
      "visual_tag_zh": "ç®€çŸ­ä¸­æ–‡æ ‡ç­¾ï¼Œä¾‹å¦‚ï¼šé»‘è¡£å¥³ä¸»ã€çº¢è‰²è·‘è½¦ã€è“è‰²æ‘©æ‰˜ã€ç™½è‰²è¶³çƒ",
      "role_zh": "ä¸»ä½“ / åæ´¾ / è·¯äºº / è¢«è¿½é€ç›®æ ‡ / éšœç¢ç‰© ç­‰",
      "action_brief_zh": "ç”¨ 1 å¥ä¸­æ–‡æè¿°è¯¥å®ä½“æ­¤åˆ»ä¸»è¦åŠ¨ä½œå’Œæ–¹å‘ï¼Œä¾‹å¦‚ï¼šæ²¿ç€å±‹é¡¶è¾¹ç¼˜å‘å³é«˜é€Ÿå¥”è·‘",
      "screen_pos_hint_zh": "æè¿°åœ¨ç”»é¢ä¸­çš„å¤§è‡´ä½ç½®ï¼Œä¾‹å¦‚ï¼šç”»é¢å·¦ä¸‹ / ç”»é¢å³ä¾§åä¸Š / å±…ä¸­åä¸‹",
      "direction_zh": "è¿åŠ¨æˆ–æœå‘çš„ä¸­æ–‡æè¿°ï¼Œä¾‹å¦‚ï¼šä»å·¦å‘å³ã€ä»è¿œå¤„å†²å‘é•œå¤´ã€å‘ç”»é¢æ·±å¤„è¿œç¦»",
      "speed_zh": "ç¼“æ…¢ / ä¸­é€Ÿ / é«˜é€Ÿ / å‡ ä¹é™æ­¢"
    }}
  ],

  "camera_motion_zh": (
    "ç”¨ 1 å¥ä¸­æ–‡æè¿°é•œå¤´è§†è§’å’Œæœºä½è¿åŠ¨ï¼Œä¾‹å¦‚ï¼šè‚©åè·Ÿæ‹äººç‰©å‘å‰å¥”è·‘çš„ä¸­æ™¯ï¼›"
    "æˆ–ï¼šä¿¯è§†è·Ÿéšé•œå¤´ä»ä¸Šæ–¹æ»‘åŠ¨è§‚å¯Ÿä¸¤è¾†è½¦çš„å¯¹å‘è¡Œé©¶ï¼›"
    "è¦æåˆ°ï¼šæ˜¯è·Ÿæ‹å“ªä¸€ä¸ªå®ä½“ã€è¿åŠ¨æ–¹å‘ï¼ˆä¾‹å¦‚ä»å·¦å‘å³æ»‘åŠ¨ï¼‰ã€æœºä½æ˜¯é«˜æœºä½ / ä½æœºä½ / å¹³è§†ã€‚"
  ),

  "interaction_zh": (
    "ç”¨ 1ï½3 å¥ä¸­æ–‡æè¿°å¤šä¸ªå®ä½“ä¹‹é—´çš„å…³ç³»ï¼Œä¾‹å¦‚ï¼šçº¢è‰²è·‘è½¦æ­£åœ¨è¿½é€å‰æ–¹é»‘è‰²è½¿è½¦ï¼›"
    "ä¸»è§’éª‘æ‘©æ‰˜ä»è¡Œäººä¹‹é—´ç©¿è¿‡ï¼›è¶³çƒè¢«çƒå‘˜è¸¢å‘çƒé—¨ï¼›"
    "å¦‚æœåŸºæœ¬æ²¡æœ‰äº’åŠ¨ï¼Œå¯ä»¥å†™â€œå„å®ä½“ä¹‹é—´å‡ ä¹æ²¡æœ‰ç›´æ¥äº’åŠ¨â€ã€‚"
  ),

  "motion_trend_zh": (
    "ç”¨ 1ï½2 å¥ä¸­æ–‡ï¼Œä»â€œä¸Šä¸€ç¬é—´ / å½“å‰ç¬é—´ / ä¸‹ä¸€ç¬é—´â€çš„è§’åº¦ï¼Œæ¨æµ‹åŠ¨ä½œå‘å±•ï¼š"
    "ä¸Šä¸€ç¬é—´åˆšåˆšå‘ç”Ÿä»€ä¹ˆï¼ˆèµ·æ­¥ / åŠ é€Ÿ / è½¬å‘ï¼‰ï¼Œå½“å‰æ˜¯å“ªä¸ªæå€¼å§¿æ€æˆ–å…³é”®æ—¶åˆ»ï¼Œ"
    "ä¸‹ä¸€ç¬é—´å¾ˆå¯èƒ½å‘ç”Ÿä»€ä¹ˆï¼ˆèµ·è·³ã€è½åœ°ã€ç¢°æ’ã€å®Œæˆè¶…è½¦ç­‰ï¼‰ã€‚"
  ),

  "motion_tags_zh": [
    "#è¿½é€",
    "#é«˜é€Ÿæ¼‚ç§»"
  ]
}}

è¦æ±‚ï¼š
1. åªè¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ï¼Œä¸è¦ä»»ä½•è§£é‡Šæˆ–é¢å¤–æ–‡å­—ã€‚
2. æ‰€æœ‰å­—ç¬¦ä¸²å¿…é¡»ä½¿ç”¨åŒå¼•å·ï¼Œä¸è¦ä½¿ç”¨å•å¼•å·ã€‚
3. JSON ä¸­ä¸èƒ½æœ‰æ³¨é‡Šï¼Œä¸èƒ½æœ‰å¤šä½™çš„é€—å·ã€‚
4. å¦‚æœç”»é¢ä¸­åªæœ‰ä¸€ä¸ªè¿åŠ¨å®ä½“ï¼Œä¹Ÿè¦ç”¨ moving_entities æ•°ç»„ï¼Œåªæ”¾ä¸€ä¸ªå¯¹è±¡ã€‚
"""
        resp = model.generate_content([prompt, img])
        text = _extract_text_from_response(resp)
        if not text:
            raise ValueError("æ¨¡å‹æœªè¿”å›æ–‡æœ¬")

        start = text.find("{")
        end = text.rfind("}")
        if start == -1 or end == -1 or end <= start:
            raise ValueError("æœªæ£€æµ‹åˆ°æœ‰æ•ˆ JSON ç»“æ„")

        json_str = text[start: end + 1]
        info = json.loads(json_str)

        # å…œåº•å­—æ®µ
        info["index"] = index
        info.setdefault("scene_motion_brief_zh", "")
        info.setdefault("moving_entities", [])
        info.setdefault("camera_motion_zh", "")
        info.setdefault("interaction_zh", "")
        info.setdefault("motion_trend_zh", "")
        info.setdefault("motion_tags_zh", [])

        return info

    except Exception as e:
        return {
            "index": index,
            "scene_motion_brief_zh": f"ï¼ˆAI åˆ†æå¤±è´¥ï¼š{e}ï¼‰",
            "moving_entities": [],
            "camera_motion_zh": "",
            "interaction_zh": "",
            "motion_trend_zh": "",
            "motion_tags_zh": [],
        }


def analyze_motions_concurrently(
    images: List[Image.Image],
    model,
    max_ai_frames: int,
) -> List[Dict[str, Any]]:
    """
    å¹¶å‘åˆ†æå¤šå¸§ï¼Œåªè·‘å‰ max_ai_framesï¼Œå…¶ä½™å¸§åšå ä½è¯´æ˜ã€‚
    """
    n = len(images)
    if n == 0:
        return []

    use_n = min(max_ai_frames, n)
    results: List[Dict[str, Any]] = [None] * n  # type: ignore

    status = st.empty()
    status.info(f"âš¡ æ­£åœ¨å¯¹å‰ {use_n} å¸§è¿›è¡Œå¤šå®ä½“è¿åŠ¨åˆ†æï¼ˆå…± {n} å¸§ï¼‰ã€‚")

    with concurrent.futures.ThreadPoolExecutor(max_workers=min(use_n, 6)) as executor:
        future_to_index = {
            executor.submit(analyze_motion_single_frame, images[i], model, i + 1): i
            for i in range(use_n)
        }
        for future in concurrent.futures.as_completed(future_to_index):
            i = future_to_index[future]
            try:
                results[i] = future.result()
            except Exception as e:
                results[i] = {
                    "index": i + 1,
                    "scene_motion_brief_zh": f"ï¼ˆAI åˆ†æå¤±è´¥ï¼š{e}ï¼‰",
                    "moving_entities": [],
                    "camera_motion_zh": "",
                    "interaction_zh": "",
                    "motion_trend_zh": "",
                    "motion_tags_zh": [],
                }

    # åé¢çš„å¸§åªåšå ä½
    for i in range(use_n, n):
        results[i] = {
            "index": i + 1,
            "scene_motion_brief_zh": "ï¼ˆæœ¬å¸§æœªåš AI è¿åŠ¨åˆ†æï¼Œç”¨äºèŠ‚çœé…é¢ï¼Œä»…ä¿ç•™ç”»é¢å‚è€ƒã€‚ï¼‰",
            "moving_entities": [],
            "camera_motion_zh": "",
            "interaction_zh": "",
            "motion_trend_zh": "",
            "motion_tags_zh": [],
        }

    status.empty()
    return results


# ========================
# æ•´æ®µè¿åŠ¨è½¨è¿¹æ¦‚æ‹¬ï¼ˆç»¼åˆç‰ˆï¼‰
# ========================

def summarize_scene_motion(
    frame_infos: List[Dict[str, Any]],
    model,
    frame_range: Optional[Tuple[int, int]] = None,
) -> str:
    """
    ç»¼åˆåœºæ™¯ï¼šè¿½é€ / è·‘é…· / è½¦æˆ ç­‰æ•´æ®µè¿åŠ¨è½¨è¿¹æ¦‚æ‹¬ã€‚
    """
    if not frame_infos:
        return "ï¼ˆæš‚æ— å…³é”®å¸§ï¼Œæ— æ³•æ¦‚æ‹¬æ•´ä½“è¿åŠ¨è½¨è¿¹ã€‚ï¼‰"

    n = len(frame_infos)
    if frame_range is None:
        start_idx, end_idx = 1, n
    else:
        start_idx, end_idx = frame_range
        start_idx = max(1, start_idx)
        end_idx = min(n, end_idx)
        if end_idx < start_idx:
            return "ï¼ˆå¸§åŒºé—´ä¸åˆæ³•ï¼Œæ— æ³•æ¦‚æ‹¬æ•´ä½“è¿åŠ¨è½¨è¿¹ã€‚ï¼‰"

    selected = frame_infos[start_idx - 1: end_idx]

    described = []
    for info in selected:
        desc = info.get("scene_motion_brief_zh", "") or ""
        if not desc:
            continue
        if "æœªåš AI è¿åŠ¨åˆ†æ" in desc or "AI åˆ†æå¤±è´¥" in desc:
            continue

        idx = info.get("index", "?")
        ents = info.get("moving_entities", []) or []
        ent_briefs = []
        for e in ents:
            vt = e.get("visual_tag_zh", "") or ""
            ab = e.get("action_brief_zh", "") or ""
            if vt or ab:
                ent_briefs.append(f"{vt}ï¼š{ab}")
        ent_text = "ï¼›".join(ent_briefs) if ent_briefs else "ï¼ˆæœªæå–åˆ°å®ä½“åŠ¨ä½œï¼‰"

        interaction = info.get("interaction_zh", "") or ""
        trend = info.get("motion_trend_zh", "") or ""

        described.append(
            f"ç¬¬ {idx} å¸§ï¼š\n"
            f"- æ•´ä½“è¿åŠ¨ç®€è¿°ï¼š{desc}\n"
            f"- å„å®ä½“åŠ¨ä½œï¼š{ent_text}\n"
            f"- å®ä½“ä¹‹é—´äº’åŠ¨ï¼š{interaction}\n"
            f"- åŠ¨ä½œè¶‹åŠ¿ï¼š{trend}"
        )

    if not described:
        return "ï¼ˆå½“å‰é€‰æ‹©çš„å¸§åŒºé—´å†…æ²¡æœ‰æœ‰æ•ˆçš„è¿åŠ¨åˆ†æï¼Œæ— æ³•ç”Ÿæˆæ¦‚æ‹¬ã€‚ï¼‰"

    joined = "\n\n".join(described)

    prompt = f"""
ä½ ç°åœ¨æ˜¯åŠ¨ä½œè®¾è®¡æ€»ç›‘ + æ±½è½¦ç‰¹æŠ€åè°ƒ + è¿åŠ¨è§„åˆ’å¸ˆã€‚
ä¸‹é¢æ˜¯ä»ä¸€æ®µè§†é¢‘ä¸­æŠ½å–çš„è‹¥å¹²è¿ç»­å…³é”®å¸§çš„â€œå¤šå®ä½“è¿åŠ¨è¯´æ˜â€ï¼ŒåŒ…æ‹¬äººç‰©ã€è½¦è¾†ã€ç‰©ä½“ç­‰ã€‚

=== è¿ç»­å¸§è¿åŠ¨è¯´æ˜å¼€å§‹ ===
{joined}
=== è¿ç»­å¸§è¿åŠ¨è¯´æ˜ç»“æŸ ===

è¯·ä¸¥æ ¼æŒ‰ä¸‹é¢ç»“æ„è¾“å‡ºä¸­æ–‡ + è‹±æ–‡åˆ†æï¼š

ã€æ•´ä½“è¿åŠ¨è½¨è¿¹æ¦‚æ‹¬ã€‘
ç”¨ 2-4 å¥ä¸­æ–‡ï¼Œä»å®è§‚è§’åº¦è¯´æ˜ï¼š
æœ‰å“ªäº›ä¸»è¦å®ä½“ï¼ˆä¾‹å¦‚ï¼šå¥³ä¸»ã€çº¢è‰²è·‘è½¦ã€é»‘è‰²æ‘©æ‰˜ã€é£è¡Œæ— äººæœºç­‰ï¼‰ï¼Œ
ä»–ä»¬åœ¨è¿™ä¸€æ®µé‡Œåˆ†åˆ«å®Œæˆäº†æ€æ ·çš„è¿åŠ¨è·¯å¾„ï¼ˆä»å“ªé‡Œæ¥ã€å¾€å“ªé‡Œå»ï¼‰ï¼Œ
æ•´ä½“æ˜¯è¿½é€ã€é€ƒè„±ã€è¶…è½¦ã€å¯¹æ’è¿˜æ˜¯é…åˆç­‰ã€‚

ã€å…³é”®äº‹ä»¶ï¼ˆæ—¶é—´é¡ºåºï¼‰ã€‘
ç”¨ 3-7 è¡Œï¼Œæ¯è¡Œå‰é¢åŠ  1ï¼‰ã€2ï¼‰â€¦ï¼Œ
æ¯è¡Œç”¨ä¸­æ–‡å†™å‡ºä¸€ä¸ªå…³é”®â€œè¿åŠ¨äº‹ä»¶â€ï¼Œ
ä¾‹å¦‚ï¼šçº¢è‰²è·‘è½¦ä»é™æ­¢æ€¥åŠ é€Ÿå†²å‡ºï¼›å¥³ä¸»ä»å±‹é¡¶ä¸€è·ƒè€Œä¸‹è½åˆ°è½¦é¡¶ï¼›ä¸¤è½¦åœ¨å¼¯é“å¤„å‘ç”Ÿè½»å¾®ç¢°æ’ç­‰ã€‚

ã€è¿åŠ¨å±‚é¢çš„é£æ ¼ä¸èŠ‚å¥ã€‘
ç”¨ 2-3 å¥ä¸­æ–‡æ€»ç»“è¿™æ®µè¿åŠ¨çš„èŠ‚å¥æ„Ÿï¼ˆæ…¢ / ä¸­ / å¿«ï¼‰ã€æ˜¯å¦æœ‰çªç„¶çš„çˆ†å‘ / åˆ¹åœ / æ¼‚ç§»ã€
æ•´ä½“æ›´åå†™å®åŠ¨ä½œè¿˜æ˜¯å¤¸å¼ ç‰¹æ•ˆã€‚

ã€SORA / Veo ç”¨æ•´æ®µè¿åŠ¨è‹±æ–‡æç¤ºè¯ã€‘
ç”¨ 3-6 å¥è‹±æ–‡æè¿°è¿™ä¸€æ•´æ®µé•œå¤´ï¼Œé‡ç‚¹å†™ï¼š
1ï¼‰æœ‰å“ªäº›å®ä½“ï¼Œä»¥åŠå®ƒä»¬çš„è§†è§‰ç‰¹å¾ï¼ˆä¾‹å¦‚ red sports car, female protagonist in black outfitï¼‰ï¼›
2ï¼‰å„å®ä½“çš„å¤§è‡´è¿åŠ¨è·¯å¾„ä¸ç›¸äº’å…³ç³»ï¼ˆchasing, overtaking, collision ç­‰ï¼‰ï¼›
3ï¼‰é•œå¤´è§†è§’å’Œæœºä½è¿åŠ¨ï¼ˆlow-angle tracking shot following the car, overhead shot revealing both lanes ç­‰ï¼‰ï¼›
4ï¼‰æ•´ä½“æ—¶é•¿ä¸æ ¼å¼ï¼šæœ€åä¸€å¥ç±»ä¼¼
"8 second continuous action shot, vertical 9:16, 24fps, cinematic, highly detailed."

ä¸è¦è¾“å‡ºå…¶ä»–ä»»ä½•å°èŠ‚æˆ–è§£é‡Šã€‚
"""
    try:
        resp = model.generate_content(prompt)
        return _extract_text_from_response(resp)
    except Exception as e:
        msg = str(e)
        if "quota" in msg or "You exceeded your current quota" in msg:
            return "æ•´ä½“è¿åŠ¨è½¨è¿¹æ¦‚æ‹¬ç”Ÿæˆå¤±è´¥ï¼šå½“å‰ Gemini å…è´¹é¢åº¦æ¯åˆ†é’Ÿè°ƒç”¨æ¬¡æ•°å·²ç”¨å®Œï¼Œè¯·å‡å°‘æœ¬æ¬¡åˆ†æå¸§æ•°æˆ–ç¨åå†è¯•ã€‚"
        return f"æ•´ä½“è¿åŠ¨è½¨è¿¹æ¦‚æ‹¬ç”Ÿæˆå¤±è´¥ï¼š{msg}"


# ========================
# ç©ºä¸­ / ç©¿è¶Šæœº / è¶…äººä¸“ç”¨æ€»ç»“
# ========================

def summarize_aerial_shot(
    frame_infos: List[Dict[str, Any]],
    model,
    frame_range: Optional[Tuple[int, int]] = None,
) -> Dict[str, Any]:
    """
    ä¸“é—¨ç”¨æ¥æ€»ç»“ï¼šæ— äººæœº / ç©¿è¶Šæœº FPV / è¶…äººé£è¡Œ / é«˜æ¥¼è·³ä¸‹ ç­‰â€œç©ºä¸­è¿åŠ¨é•œå¤´â€ã€‚
    è¿”å›ï¼š
      {
        "shot_category": "aerial_fpv_or_superhero",
        "aerial_summary_zh": "...",
        "aerial_meta": {...},
        "aerial_prompt_en": "..."
      }
    """
    if not frame_infos:
        return {
            "shot_category": "aerial_fpv_or_superhero",
            "aerial_summary_zh": "ï¼ˆæš‚æ— å…³é”®å¸§ï¼Œæ— æ³•æ¦‚æ‹¬ç©ºä¸­é•œå¤´ã€‚ï¼‰",
            "aerial_meta": {},
            "aerial_prompt_en": "",
        }

    n = len(frame_infos)
    if frame_range is None:
        start_idx, end_idx = 1, n
    else:
        start_idx, end_idx = frame_range
        start_idx = max(1, start_idx)
        end_idx = min(n, end_idx)
        if end_idx < start_idx:
            return {
                "shot_category": "aerial_fpv_or_superhero",
                "aerial_summary_zh": "ï¼ˆå¸§åŒºé—´ä¸åˆæ³•ï¼Œæ— æ³•æ¦‚æ‹¬ç©ºä¸­é•œå¤´ã€‚ï¼‰",
                "aerial_meta": {},
                "aerial_prompt_en": "",
            }

    selected = frame_infos[start_idx - 1: end_idx]

    described = []
    for info in selected:
        desc = info.get("scene_motion_brief_zh", "") or ""
        if not desc:
            continue
        if "æœªåš AI è¿åŠ¨åˆ†æ" in desc or "AI åˆ†æå¤±è´¥" in desc:
            continue

        idx = info.get("index", "?")
        ents = info.get("moving_entities", []) or []
        ent_lines = []
        for e in ents:
            vt = e.get("visual_tag_zh", "") or ""
            etype = e.get("type", "") or ""
            act = e.get("action_brief_zh", "") or ""
            pos = e.get("screen_pos_hint_zh", "") or ""
            direction = e.get("direction_zh", "") or ""
            speed = e.get("speed_zh", "") or ""
            if vt or act:
                ent_lines.append(
                    f"- å®ä½“ï¼š{vt}ï¼ˆç±»å‹ï¼š{etype}ï¼‰ï¼ŒåŠ¨ä½œï¼š{act}ï¼Œç”»é¢ä½ç½®ï¼š{pos}ï¼Œæ–¹å‘ï¼š{direction}ï¼Œé€Ÿåº¦ï¼š{speed}"
                )

        camera = info.get("camera_motion_zh", "") or ""
        interaction = info.get("interaction_zh", "") or ""
        trend = info.get("motion_trend_zh", "") or ""

        described.append(
            f"ç¬¬ {idx} å¸§ï¼š\n"
            f"ã€æ•´ä½“è¿åŠ¨ç®€è¿°ã€‘{desc}\n"
            f"ã€å„å®ä½“è¿åŠ¨ã€‘\n" + ("\n".join(ent_lines) if ent_lines else "ï¼ˆæœªæå–åˆ°å®ä½“è¿åŠ¨ç»†èŠ‚ï¼‰") + "\n"
            f"ã€é•œå¤´è¿åŠ¨ã€‘{camera}\n"
            f"ã€å®ä½“ä¹‹é—´äº’åŠ¨ã€‘{interaction}\n"
            f"ã€åŠ¨ä½œè¶‹åŠ¿ã€‘{trend}"
        )

    if not described:
        return {
            "shot_category": "aerial_fpv_or_superhero",
            "aerial_summary_zh": "ï¼ˆå½“å‰åŒºé—´å†…æ²¡æœ‰æœ‰æ•ˆçš„è¿åŠ¨åˆ†æï¼Œæ— æ³•ç”Ÿæˆç©ºä¸­é•œå¤´æ¦‚æ‹¬ã€‚ï¼‰",
            "aerial_meta": {},
            "aerial_prompt_en": "",
        }

    joined = "\n\n".join(described)

    prompt = f"""
ä½ ç°åœ¨æ˜¯ï¼šé¡¶çº§æ— äººæœº / ç©¿è¶Šæœº FPV æœºæ‰‹ + ç‰¹æŠ€åè°ƒ + ç”µå½±æ‘„å½±æŒ‡å¯¼ + åˆ†é•œæ€»ç›‘ã€‚

ä¸‹é¢æ˜¯ä¸€æ®µç©ºä¸­/é£è¡Œç›¸å…³é•œå¤´çš„è‹¥å¹²å…³é”®å¸§çš„è¿åŠ¨è¯´æ˜ï¼ˆåŒ…æ‹¬äººç‰©ã€è½¦è¾†ã€è¶…äººã€ç©¿è¶Šæœºç­‰ï¼‰ï¼š

=== ç©ºä¸­é•œå¤´å¸§çº§è¯´æ˜å¼€å§‹ ===
{joined}
=== ç©ºä¸­é•œå¤´å¸§çº§è¯´æ˜ç»“æŸ ===

è¯·å¸®æˆ‘ä»â€œç©ºä¸­é•œå¤´è®¾è®¡â€çš„è§’åº¦ï¼Œè¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ï¼Œå­—æ®µå¦‚ä¸‹ï¼ˆæ‰€æœ‰ key å¿…é¡»å‡ºç°ï¼‰ï¼š

{{
  "shot_category": "aerial_fpv_or_superhero",

  "aerial_summary_zh": "ç”¨ 2ï½4 å¥ä¸­æ–‡ï¼Œä»å®è§‚è§’åº¦æ¦‚æ‹¬ï¼šè¿™ä¸€æ®µç©ºä¸­é•œå¤´é‡Œæœ‰å“ªäº›ä¸»ä½“ï¼ˆäººç‰©/è½¦/é£è¡Œå™¨ï¼‰ï¼Œå®ƒä»¬åœ¨åŸå¸‚/å±±è°·/å®¤å†…å¤–ä¹‹é—´å®Œæˆäº†æ€æ ·çš„é£è¡Œ/å è½/ä¸Šå‡è·¯å¾„ï¼Œä»¥åŠæ•´ä½“æƒ…ç»ªï¼ˆåˆºæ¿€/å±é™©/è‡ªç”±/æ¢¦å¹»ç­‰ï¼‰ã€‚",

  "aerial_meta": {{
    "flight_path_zh": "ç”¨ 2ï½4 å¥ä¸­æ–‡æè¿°é£è¡Œè·¯å¾„ï¼šä»å“ªå„¿å‡ºå‘ï¼ˆåœ°é¢/æ¥¼é¡¶/å®¤å†…ï¼‰ï¼Œé«˜åº¦å¦‚ä½•å˜åŒ–ï¼ˆè´´åœ°â†’åŠç©ºâ†’é«˜ç©ºâ†’å†ä¿¯å†²å›åœ°é¢ï¼‰ï¼Œå¤§è‡´æ²¿ç€ä»€ä¹ˆè·¯çº¿ï¼ˆæ²¿è¡—é“/é¡ºç€å³¡è°·/å›´ç»•é«˜æ¥¼è½¬åœˆï¼‰ã€‚",
    "altitude_profile_zh": "ä¸“é—¨ç”¨ 1ï½2 å¥ä¸­æ–‡æè¿°â€œé«˜åº¦æ›²çº¿â€ï¼šä¾‹å¦‚ï¼šä¸€å¼€å§‹å‡ ä¹è´´åœ°é£è¡Œï¼Œéšåæ²¿å¤§æ¥¼å¤–ç«‹é¢æŒç»­æ‹‰å‡åˆ°é«˜ç©ºï¼Œå†ç¿»è¶Šæ¥¼é¡¶ä¿¯å†²å›åˆ°è¡—é¢é«˜åº¦ã€‚",
    "drone_attitude_zh": "ç”¨ 2ï½3 å¥ä¸­æ–‡æè¿°æœºä½“å§¿æ€ï¼šæ»šè½¬ï¼ˆrollï¼‰ã€ä¿¯ä»°ï¼ˆpitchï¼‰ã€åèˆªï¼ˆyawï¼‰ä»¥åŠåœ°å¹³çº¿æ˜¯å¦é•¿æ—¶é—´å€¾æ–œï¼ˆå…¸å‹ FPV é£æ ¼ï¼‰ã€‚ä¾‹å¦‚ï¼šæœºä½“é•¿æ—¶é—´å³ä¾§å€¾çº¦ 30Â°ï¼Œåœ¨ä¿¯å†²ç¬é—´å¿«é€Ÿç”±å³å€¾åˆ‡åˆ°å·¦å€¾å¹¶ä¼´éšçŸ­æš‚ç¿»æ»šã€‚",
    "speed_profile_zh": "ç”¨ 2ï½3 å¥ä¸­æ–‡æè¿°é€Ÿåº¦æ›²çº¿ï¼šèµ·é£é˜¶æ®µä»é™æ­¢åˆ°é«˜é€Ÿã€ä¿¯å†²æ—¶çš„çˆ†å‘åŠ é€Ÿã€æ¥è¿‘ç›®æ ‡æ—¶çš„æ€¥å‰§å‡é€Ÿã€æ˜¯å¦æœ‰æ…¢åŠ¨ä½œç‰‡æ®µï¼ˆspeed rampï¼‰ã€‚",
    "proximity_events_zh": "ç”¨ 2ï½4 å¥ä¸­æ–‡åˆ—å‡ºæœ€é‡è¦çš„â€œæ“¦è¾¹/ç©¿è¶Š/é™©è€Œåˆé™©â€çš„ç¬é—´ï¼šä¾‹å¦‚è´´ç€æ¥¼ä½“ä¹‹é—´çš„çª„ç¼é£è¿‡ã€ä»å¹¿å‘Šç‰Œåº•ä¸‹é’»è¿‡å»ã€ç©¿ç ´ç»ç’ƒçª—ã€é«˜é€Ÿæ è¿‡æ ‘æ¢¢ï¼Œå†™æ¸…æ¥šâ€œç¦»éšœç¢ç‰©å¾ˆè¿‘â€çš„æ„Ÿè§‰ã€‚",
    "subject_lock_zh": "ç”¨ 1ï½2 å¥ä¸­æ–‡æè¿°é•œå¤´å¯¹ä¸»ä½“çš„é”å®šæ–¹å¼ï¼šå¼ºé”äººç‰©/è½¦è¾†ï¼ˆä¸»ä½“åŸºæœ¬å±…ä¸­ï¼‰ã€è¿˜æ˜¯æ›´åå‘å±•ç¤ºç¯å¢ƒï¼ˆä¸»ä½“åªæ˜¯ç”»é¢ä¸­çš„ä¸€éƒ¨åˆ†ï¼‰ï¼›ä»¥åŠè·Ÿæ‹æ˜¯è´´èƒŒã€è´´ä¾§ã€è¿˜æ˜¯ç•¥é¢†å…ˆåŠä¸ªèº«ä½ã€‚",
    "vertical_action_phases_zh": "å¦‚æœæœ‰â€œé«˜æ¥¼è·³ä¸‹ / è¶…äººèµ·é£ / å‚ç›´é£è¡Œâ€ï¼Œç”¨ 3ï½5 ä¸ªé˜¶æ®µæ‹†è§£ï¼šèµ·åŠ¿â†’è…¾ç©ºâ†’è‡ªç”±è½ä½“æˆ–çˆ¬å‡â†’å¹³é£/è½åœ°ï¼Œå¹¶è¯´æ˜æ¯ä¸ªé˜¶æ®µé•œå¤´é«˜åº¦å’Œè§†è§’å¦‚ä½•å˜åŒ–ã€‚",
    "special_camera_moves_zh": "ç”¨ 2ï½4 å¥ä¸­æ–‡æè¿°ç‰¹åˆ«çš„è¿é•œæŠ€å·§ï¼šç”©é•œè½¬åœºï¼ˆwhip panï¼‰ã€æ•´åœˆæ»šè½¬ï¼ˆbarrel rollï¼‰ã€é®æŒ¡è½¬åœºï¼ˆè´´è¿‘é»‘å¢™è¿›å…¥ä¸‹ä¸€åœºæ™¯ï¼‰ã€ä»è·Ÿè½¦åˆ‡æ¢åˆ°è·Ÿäººç­‰ã€‚"
  }},

  "aerial_prompt_en": "ç”¨ 3ï½6 å¥è‹±æ–‡ï¼Œå†™ä¸€æ®µé€‚åˆç›´æ¥ç»™ SORA / Veo çš„ç©ºä¸­é•œå¤´æç¤ºè¯ï¼š\\n1ï¼‰å…ˆç”¨ 1 å¥ç‚¹åä¸»è¦ä¸»ä½“å’Œç¯å¢ƒï¼Œä¾‹å¦‚ï¼šan FPV drone follows a black-clad female protagonist leaping off a skyscraper in a neon city...ï¼›\\n2ï¼‰ç”¨ 2ï½3 å¥è¯¦ç»†æè¿°é£è¡Œè·¯å¾„ï¼ˆheight changes, path around/through buildings, near missesï¼‰å’Œæœºä½“å§¿æ€ï¼ˆtilted horizon, roll, diveï¼‰ï¼›\\n3ï¼‰æœ€åä¸€ä¸¤å¥äº¤ä»£æ•´ä½“èŠ‚å¥å’Œå‚æ•°ï¼Œä¾‹å¦‚ï¼šfast, immersive FPV shot with one brief slow-motion moment during the dive. 8 second continuous aerial shot, vertical 9:16, 24fps, cinematic, highly detailed."
}}

è¦æ±‚ï¼š
1. åªè¾“å‡ºè¿™ä¸€ä¸ª JSON å¯¹è±¡ï¼Œä¸è¦ä»»ä½•è§£é‡Šæˆ–é¢å¤–æ–‡å­—ã€‚
2. æ‰€æœ‰å­—ç¬¦ä¸²å¿…é¡»ä½¿ç”¨åŒå¼•å·ï¼Œä¸è¦ä½¿ç”¨å•å¼•å·ã€‚
3. JSON ä¸­ä¸èƒ½æœ‰æ³¨é‡Šï¼Œä¸èƒ½æœ‰å¤šä½™çš„é€—å·ã€‚
"""
    try:
        resp = model.generate_content(prompt)
        text = _extract_text_from_response(resp)
        if not text:
            raise ValueError("æ¨¡å‹æœªè¿”å›æ–‡æœ¬")

        start = text.find("{")
        end = text.rfind("}")
        if start == -1 or end == -1 or end <= start:
            raise ValueError("æœªæ£€æµ‹åˆ°æœ‰æ•ˆ JSON ç»“æ„")

        json_str = text[start: end + 1]
        data = json.loads(json_str)

        data.setdefault("shot_category", "aerial_fpv_or_superhero")
        data.setdefault("aerial_summary_zh", "")
        data.setdefault("aerial_meta", {})
        data.setdefault("aerial_prompt_en", "")
        if not isinstance(data["aerial_meta"], dict):
            data["aerial_meta"] = {}

        return data

    except Exception as e:
        return {
            "shot_category": "aerial_fpv_or_superhero",
            "aerial_summary_zh": f"ç©ºä¸­é•œå¤´æ¦‚æ‹¬å¤±è´¥ï¼š{e}",
            "aerial_meta": {},
            "aerial_prompt_en": "",
        }


# ========================
# ä¾§è¾¹æ ï¼šAPI Key & å‚æ•°
# ========================

with st.sidebar:
    st.header("ğŸ”‘ ç¬¬ä¸€æ­¥ï¼šé…ç½® Gemini API Key")
    api_key = st.text_input(
        "è¾“å…¥ Google API Key",
        type="password",
        value=st.session_state["api_key"],
        help="ç²˜è´´ä½ çš„ Gemini API Keyï¼ˆé€šå¸¸ä»¥ AIza å¼€å¤´ï¼‰",
    )
    st.session_state["api_key"] = api_key

    st.markdown("---")
    max_ai_frames = st.slider(
        "æœ¬æ¬¡æœ€å¤šåˆ†æçš„å…³é”®å¸§æ•°é‡ï¼ˆæ¶ˆè€—é…é¢ï¼‰",
        min_value=4,
        max_value=20,
        value=10,
        step=1,
    )
    st.caption("å»ºè®®ï¼š10 ç§’è§†é¢‘ 6~10 å¸§å°±è¶³å¤Ÿåˆ†ææ•´ä½“è¿åŠ¨ã€‚")

    st.markdown("---")
    st.markdown("â± åˆ†ææ—¶é—´èŒƒå›´ï¼ˆå•ä½ï¼šç§’ï¼‰")
    start_sec = st.number_input(
        "ä»ç¬¬å‡ ç§’å¼€å§‹ï¼ˆå«ï¼‰", min_value=0.0, value=0.0, step=0.5,
        help="ç²¾ç¡®åˆ° 0.5 ç§’ï¼›é»˜è®¤ 0 è¡¨ç¤ºä»å¤´å¼€å§‹"
    )
    end_sec = st.number_input(
        "åˆ°ç¬¬å‡ ç§’ç»“æŸï¼ˆ0 æˆ– â‰¤å¼€å§‹ç§’ è¡¨ç¤ºç›´åˆ°ç»“å°¾ï¼‰",
        min_value=0.0, value=0.0, step=0.5,
        help="ä¾‹å¦‚åªçœ‹ 3~8 ç§’ï¼Œå°±å¡« 3 å’Œ 8ï¼›å¡« 0 åˆ™åˆ†æåˆ°ç»“å°¾"
    )

    st.markdown("---")
    shot_type = st.selectbox(
        "é•œå¤´ç±»å‹ / åˆ†æä¾§é‡ç‚¹",
        [
            "é»˜è®¤ï¼šç»¼åˆè¿åŠ¨åˆ†æ",
            "ç©ºä¸­/ç©¿è¶Šæœº/è¶…äººé•œå¤´ï¼ˆå¼ºåŒ–é£è¡Œè½¨è¿¹ï¼‰",
        ],
    )

    if not api_key:
        st.warning("ğŸ”´ è¿˜æ²¡æœ‰ Keyï¼Œå…ˆå» https://ai.google.dev/ ç”³è¯·ä¸€ä¸ªã€‚")
    else:
        st.success("ğŸŸ¢ Key å·²å°±ç»ªï¼Œå¯ä»¥åˆ†æã€‚")


# ========================
# åˆå§‹åŒ– Gemini æ¨¡å‹
# ========================

model = None
if api_key:
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(GEMINI_MODEL_NAME)
    except Exception as e:
        st.error(f"âŒ åˆå§‹åŒ– Gemini æ¨¡å‹å¤±è´¥ï¼š{e}")
        model = None


# ========================
# ä¸»ç•Œé¢ï¼šè§†é¢‘æ¥æº
# ========================

source_mode = st.radio(
    "ğŸ“¥ é€‰æ‹©è§†é¢‘æ¥æº",
    ["ä¸Šä¼ æœ¬åœ°æ–‡ä»¶", "è¾“å…¥ç½‘ç»œè§†é¢‘é“¾æ¥ï¼ˆæŠ–éŸ³ / Bç«™ / TikTok / YouTubeï¼‰"],
    index=0,
)

video_url: Optional[str] = None
uploaded_file = None

if source_mode == "ä¸Šä¼ æœ¬åœ°æ–‡ä»¶":
    uploaded_file = st.file_uploader(
        "ğŸ“‚ ä¸Šä¼ è§†é¢‘æ–‡ä»¶ï¼ˆå»ºè®® < 50MBï¼‰",
        type=["mp4", "mov", "m4v", "avi", "mpeg"],
    )
else:
    video_url = st.text_input(
        "ğŸ”— è¾“å…¥è§†é¢‘é“¾æ¥",
        placeholder="ä¾‹å¦‚ï¼šhttps://v.douyin.com/xxxxxx æˆ– https://www.douyin.com/video/xxxxxxxxx",
    )

# ========================
# ä¸»æŒ‰é’®é€»è¾‘
# ========================

if st.button("ğŸš€ å¼€å§‹åˆ†æè§†é¢‘è¿åŠ¨ä¸è¿é•œ"):
    if not api_key or model is None:
        st.error("è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥æœ‰æ•ˆçš„ Google API Keyã€‚")
    else:
        tmp_path: Optional[str] = None
        source_label = ""
        source_type = ""

        try:
            # 1. å‡†å¤‡è§†é¢‘
            if source_mode == "ä¸Šä¼ æœ¬åœ°æ–‡ä»¶":
                source_type = "upload"
                if not uploaded_file:
                    st.error("è¯·å…ˆä¸Šä¼ ä¸€ä¸ªè§†é¢‘æ–‡ä»¶ã€‚")
                    st.stop()
                suffix = os.path.splitext(uploaded_file.name)[1] or ".mp4"
                with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                    tmp.write(uploaded_file.read())
                    tmp_path = tmp.name
                source_label = uploaded_file.name
            else:
                source_type = "url"
                if not video_url:
                    st.error("è¯·è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„è§†é¢‘é“¾æ¥ã€‚")
                    st.stop()
                st.info("ğŸŒ æ­£åœ¨ä»ç½‘ç»œä¸‹è½½è§†é¢‘...")
                tmp_path = download_video_from_url(video_url)
                source_label = video_url

            if not tmp_path:
                st.error("è§†é¢‘è·¯å¾„å¼‚å¸¸ï¼Œè¯·é‡è¯•ã€‚")
            else:
                # 2. æŠ½å¸§
                st.info("â³ æ­£åœ¨æŠ½å–å…³é”®å¸§...")
                images, duration, used_range = extract_keyframes_dynamic(
                    tmp_path,
                    start_sec=start_sec,
                    end_sec=end_sec if end_sec > 0 else None,
                )
                start_used, end_used = used_range

                try:
                    os.remove(tmp_path)
                except OSError:
                    pass

                if not images:
                    st.error("âŒ æ— æ³•ä»è§†é¢‘ä¸­è¯»å–å¸§ï¼Œè¯·æ£€æŸ¥è§†é¢‘æ˜¯å¦æŸåæˆ–æ ¼å¼å¼‚å¸¸ã€‚")
                    st.stop()

                st.success(
                    f"âœ… å·²æŠ½å– {len(images)} ä¸ªå…³é”®å¸§ï¼ˆè§†é¢‘æ€»é•¿çº¦ {duration:.1f} ç§’ï¼Œ"
                    f"æœ¬æ¬¡åˆ†æåŒºé—´ï¼š{start_used:.1f}â€“{end_used:.1f} ç§’ï¼‰ã€‚"
                )

                # 3. æ§åˆ¶æœ¬æ¬¡ AI è°ƒç”¨æ¬¡æ•°ï¼ˆ1 æ¬¡æ•´æ®µæ€»ç»“ + å¤šå¸§åˆ†æï¼‰
                overhead_calls = 1  # æ•´æ®µæ¦‚æ‹¬ï¼ˆç»¼åˆ or ç©ºä¸­ï¼‰
                max_ai_frames_safe = max(
                    1,
                    min(max_ai_frames, FREE_TIER_RPM_LIMIT - overhead_calls),
                )
                if max_ai_frames_safe < max_ai_frames:
                    st.info(
                        f"ä¸ºé¿å…è§¦å‘å…è´¹é¢åº¦é™åˆ¶ï¼Œæœ¬æ¬¡åªå¯¹ **å‰ {max_ai_frames_safe} å¸§** åšè¿åŠ¨åˆ†æ "
                        f"ï¼ˆä¾§è¾¹æ è®¾ç½®ä¸º {max_ai_frames} å¸§ï¼‰ã€‚"
                    )

                # 4. å¸§çº§è¿åŠ¨åˆ†æ
                with st.spinner("ğŸ§  æ­£åœ¨åˆ†ææ¯ä¸€å¸§çš„å¤šå®ä½“è¿åŠ¨..."):
                    frame_infos = analyze_motions_concurrently(
                        images, model, max_ai_frames_safe
                    )

                # 5. æ•´æ®µæ¦‚æ‹¬ï¼šæ ¹æ®é•œå¤´ç±»å‹é€‰æ‹©ä¸åŒç­–ç•¥
                motion_summary: Optional[str] = None
                aerial_result: Optional[Dict[str, Any]] = None

                if shot_type == "ç©ºä¸­/ç©¿è¶Šæœº/è¶…äººé•œå¤´ï¼ˆå¼ºåŒ–é£è¡Œè½¨è¿¹ï¼‰":
                    with st.spinner("ğŸ›© æ­£åœ¨æ•´ç†ç©ºä¸­/ç©¿è¶Šæœº/è¶…äººé•œå¤´çš„é£è¡Œè½¨è¿¹ä¸æœºä½è®¾è®¡..."):
                        aerial_result = summarize_aerial_shot(
                            frame_infos, model, frame_range=None
                        )
                else:
                    with st.spinner("ğŸ® æ­£åœ¨æ•´ç†æ•´æ®µè¿åŠ¨è½¨è¿¹ä¸å…³é”®äº‹ä»¶..."):
                        motion_summary = summarize_scene_motion(
                            frame_infos, model, frame_range=None
                        )

                # 6. ç»„è£…å¯¼å‡ºæ•°æ®
                export_frames = []
                for info in frame_infos:
                    export_frames.append(
                        {
                            "index": info.get("index"),
                            "scene_motion_brief_zh": info.get("scene_motion_brief_zh", ""),
                            "moving_entities": info.get("moving_entities", []),
                            "camera_motion_zh": info.get("camera_motion_zh", ""),
                            "interaction_zh": info.get("interaction_zh", ""),
                            "motion_trend_zh": info.get("motion_trend_zh", ""),
                            "motion_tags_zh": info.get("motion_tags_zh", []),
                        }
                    )

                export_data: Dict[str, Any] = {
                    "meta": {
                        "model": GEMINI_MODEL_NAME,
                        "frame_count": len(images),
                        "max_ai_frames_this_run": max_ai_frames_safe,
                        "duration_sec_est": duration,
                        "start_sec_used": start_used,
                        "end_sec_used": end_used,
                        "source_type": source_type,
                        "source_label": source_label,
                        "shot_type": "aerial" if aerial_result else "general",
                    },
                    "frames": export_frames,
                    "overall_motion_summary": motion_summary if motion_summary else "",
                    "aerial_analysis": aerial_result if aerial_result else {},
                }

                json_str = json.dumps(export_data, ensure_ascii=False, indent=2)

                # å†™å…¥å†å²
                history = st.session_state["analysis_history"]
                run_id = f"run_{len(history) + 1}"
                history.append(
                    {
                        "id": run_id,
                        "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "meta": export_data["meta"],
                        "data": export_data,
                    }
                )
                st.session_state["analysis_history"] = history

                # 7. Tabs å±•ç¤º
                tab_frames, tab_summary, tab_json, tab_history = st.tabs(
                    [
                        "ğŸ é€å¸§å¤šå®ä½“è¿åŠ¨",
                        "ğŸ¯ æ•´æ®µæ€»ç»“ï¼ˆè¿åŠ¨ / ç©ºä¸­é•œå¤´ï¼‰",
                        "ğŸ“¦ JSON å¯¼å‡ºï¼ˆæœ¬æ¬¡ï¼‰",
                        "ğŸ•˜ å†å²è®°å½•ï¼ˆæœ¬ä¼šè¯ï¼‰",
                    ]
                )

                # --- Tab1ï¼šé€å¸§ ---
                with tab_frames:
                    st.markdown(
                        f"å…±æŠ½å– **{len(images)}** å¸§ï¼Œå…¶ä¸­å‰ **{min(len(images), max_ai_frames_safe)}** å¸§åšäº† AI è¿åŠ¨åˆ†æã€‚"
                    )
                    st.markdown("---")

                    for i, (img, info) in enumerate(zip(images, frame_infos)):
                        with st.container():
                            st.markdown(f"### ğŸ ç¬¬ {i + 1} å¸§")

                            c1, c2 = st.columns([1.2, 2])

                            with c1:
                                st.image(
                                    img,
                                    caption=f"ç¬¬ {i + 1} å¸§ç”»é¢",
                                    use_column_width=True,
                                )

                            with c2:
                                st.markdown("**æœ¬å¸§æ•´ä½“è¿åŠ¨ç®€è¿°ï¼š**")
                                st.code(
                                    info.get("scene_motion_brief_zh", ""),
                                    language="markdown",
                                )

                                entities = info.get("moving_entities", []) or []
                                if entities:
                                    st.markdown("**è¿åŠ¨å®ä½“åˆ—è¡¨ï¼ˆå¯å¤åˆ¶åˆ°åˆ†é•œ / æç¤ºè¯ï¼‰ï¼š**")
                                    lines = []
                                    for e in entities:
                                        eid = e.get("id", "")
                                        etype = e.get("type", "")
                                        vtag = e.get("visual_tag_zh", "")
                                        role = e.get("role_zh", "")
                                        act = e.get("action_brief_zh", "")
                                        pos = e.get("screen_pos_hint_zh", "")
                                        direction = e.get("direction_zh", "")
                                        speed = e.get("speed_zh", "")
                                        lines.append(
                                            f"- [{eid}] ({etype}) {vtag}ï½œè§’è‰²ï¼š{role}ï½œåŠ¨ä½œï¼š{act}ï½œä½ç½®ï¼š{pos}ï½œæ–¹å‘ï¼š{direction}ï½œé€Ÿåº¦ï¼š{speed}"
                                        )
                                    st.code("\n".join(lines), language="markdown")
                                else:
                                    st.info("æœ¬å¸§æœªè¯†åˆ«å‡ºæ˜æ˜¾çš„è¿åŠ¨å®ä½“ï¼ˆæˆ–æœªåš AI åˆ†æï¼‰ã€‚")

                                st.markdown("**é•œå¤´è§†è§’ä¸æœºä½è¿åŠ¨ï¼š**")
                                st.code(
                                    info.get("camera_motion_zh")
                                    or "ï¼ˆæš‚æ— é•œå¤´è¿åŠ¨æè¿°ï¼‰",
                                    language="markdown",
                                )

                                st.markdown("**å®ä½“ä¹‹é—´äº’åŠ¨å…³ç³»ï¼š**")
                                st.code(
                                    info.get("interaction_zh")
                                    or "ï¼ˆæš‚æ— äº’åŠ¨æè¿°ï¼‰",
                                    language="markdown",
                                )

                                st.markdown("**åŠ¨ä½œè¶‹åŠ¿ï¼ˆä¸Šä¸€ç¬é—´ / ä¸‹ä¸€ç¬é—´ï¼‰ï¼š**")
                                st.code(
                                    info.get("motion_trend_zh")
                                    or "ï¼ˆæš‚æ— åŠ¨ä½œè¶‹åŠ¿æè¿°ï¼‰",
                                    language="markdown",
                                )

                                tags = info.get("motion_tags_zh") or []
                                if tags:
                                    st.markdown("**è¿åŠ¨ç›¸å…³æ ‡ç­¾ï¼š**")
                                    st.code(" ".join(tags), language="markdown")

                            st.markdown("---")

                # --- Tab2ï¼šæ•´æ®µæ€»ç»“ ---
                with tab_summary:
                    if aerial_result:
                        st.markdown("### ğŸ›© ç©ºä¸­ / ç©¿è¶Šæœº / è¶…äººé•œå¤´æ¦‚æ‹¬ï¼ˆä¸­æ–‡ï¼‰")
                        st.code(
                            aerial_result.get("aerial_summary_zh", ""),
                            language="markdown",
                        )

                        st.markdown("### ğŸ“ é£è¡Œè·¯å¾„ / é«˜åº¦æ›²çº¿ / æœºä½“å§¿æ€ ç­‰ç»†èŠ‚")
                        meta = aerial_result.get("aerial_meta", {}) or {}
                        meta_text_lines = []
                        for k, v in meta.items():
                            if not v:
                                continue
                            meta_text_lines.append(f"ã€{k}ã€‘\n{v}\n")
                        st.code(
                            "\n".join(meta_text_lines)
                            or "ï¼ˆæš‚æ— æ›´ç»†è‡´çš„ç©ºä¸­é•œå¤´å…ƒä¿¡æ¯ï¼‰",
                            language="markdown",
                        )

                        st.markdown("### ğŸ¥ ç©ºä¸­é•œå¤´è‹±æ–‡æç¤ºè¯ï¼ˆç›´æ¥ç»™ SORA / Veoï¼‰")
                        st.code(
                            aerial_result.get("aerial_prompt_en", "")
                            or "ï¼ˆæš‚æ— ç©ºä¸­é•œå¤´è‹±æ–‡æç¤ºè¯ï¼‰",
                            language="markdown",
                        )
                    else:
                        st.markdown("### ğŸ® æ•´æ®µè¿åŠ¨è½¨è¿¹ + å…³é”®äº‹ä»¶ + è‹±æ–‡æç¤ºè¯")
                        st.code(
                            motion_summary or "ï¼ˆæš‚æ— æ•´æ®µè¿åŠ¨è½¨è¿¹æ¦‚æ‹¬ï¼‰",
                            language="markdown",
                        )

                # --- Tab3ï¼šJSON å¯¼å‡º ---
                with tab_json:
                    st.markdown("### ğŸ“¦ ä¸‹è½½æœ¬æ¬¡è¿åŠ¨åˆ†æ JSON")
                    st.download_button(
                        label="â¬‡ï¸ ä¸‹è½½ motion_analysis.json",
                        data=json_str,
                        file_name="motion_analysis.json",
                        mime="application/json",
                    )

                    with st.expander("ğŸ” é¢„è§ˆéƒ¨åˆ† JSON å†…å®¹"):
                        preview = json_str[:3000] + (
                            "\n...\n" if len(json_str) > 3000 else ""
                        )
                        st.code(preview, language="json")

                # --- Tab4ï¼šå†å²è®°å½• ---
                with tab_history:
                    st.markdown("### ğŸ•˜ å½“å‰ä¼šè¯å†å²è®°å½•ï¼ˆåˆ·æ–°é¡µé¢ä¼šæ¸…ç©ºï¼‰")

                    history = st.session_state.get("analysis_history", [])
                    if not history:
                        st.info("å½“å‰ä¼šè¯è¿˜æ²¡æœ‰ä»»ä½•å†å²è®°å½•ã€‚")
                    else:
                        options = [
                            f"{len(history) - i}. {h['created_at']} | {h['meta'].get('source_label','')} | "
                            f"{h['meta'].get('frame_count',0)} å¸§ | åŒºé—´ {h['meta'].get('start_sec_used',0):.1f}-{h['meta'].get('end_sec_used',0):.1f}s | "
                            f"ç±»å‹ï¼š{h['meta'].get('shot_type','')}"
                            for i, h in enumerate(reversed(history))
                        ]
                        idx_display = st.selectbox(
                            "é€‰æ‹©ä¸€æ¡å†å²è®°å½•æŸ¥çœ‹",
                            options=list(range(len(history))),
                            format_func=lambda i: options[i],
                        )
                        real_index = len(history) - 1 - idx_display
                        selected = history[real_index]

                        st.markdown(
                            f"**IDï¼š** `{selected['id']}`  \n"
                            f"**æ—¶é—´ï¼š** {selected['created_at']}  \n"
                            f"**æ¥æºç±»å‹ï¼š** {selected['meta'].get('source_type','')}  \n"
                            f"**æ¥æºæ ‡è¯†ï¼š** {selected['meta'].get('source_label','')}  \n"
                            f"**åˆ†æåŒºé—´ï¼š** {selected['meta'].get('start_sec_used',0):.1f}â€“{selected['meta'].get('end_sec_used',0):.1f} ç§’  \n"
                            f"**å¸§æ•°ï¼š** {selected['meta'].get('frame_count',0)}  \n"
                            f"**é•œå¤´ç±»å‹ï¼š** {selected['meta'].get('shot_type','')}  \n"
                            f"**æ¨¡å‹ï¼š** {selected['meta'].get('model','')}"
                        )

                        st.markdown("#### æ•´æ®µæ€»ç»“é¢„è§ˆ")
                        data = selected["data"]
                        if data.get("aerial_analysis"):
                            st.markdown("**ç©ºä¸­é•œå¤´æ¦‚æ‹¬ï¼ˆä¸­æ–‡ï¼‰ï¼š**")
                            st.code(
                                data["aerial_analysis"].get("aerial_summary_zh", ""),
                                language="markdown",
                            )
                            st.markdown("**ç©ºä¸­é•œå¤´è‹±æ–‡æç¤ºè¯ï¼š**")
                            st.code(
                                data["aerial_analysis"].get("aerial_prompt_en", ""),
                                language="markdown",
                            )
                        else:
                            st.markdown("**æ•´æ®µè¿åŠ¨è½¨è¿¹ï¼ˆç»¼åˆç‰ˆï¼‰ï¼š**")
                            st.code(
                                data.get("overall_motion_summary", ""),
                                language="markdown",
                            )

                        frames = data.get("frames", [])
                        if frames:
                            st.markdown("#### éƒ¨åˆ†å¸§é¢„è§ˆï¼ˆè¿åŠ¨å®ä½“ + äº’åŠ¨ï¼‰")
                            for f in frames[:3]:
                                st.markdown(f"**ç¬¬ {f.get('index')} å¸§ï¼š**")
                                st.write(f.get("scene_motion_brief_zh", ""))
                                entities = f.get("moving_entities", []) or []
                                if entities:
                                    lines = []
                                    for e in entities:
                                        vt = e.get("visual_tag_zh", "")
                                        act = e.get("action_brief_zh", "")
                                        lines.append(f"- {vt}ï¼š{act}")
                                    st.code("\n".join(lines), language="markdown")
                                st.code(
                                    f.get("interaction_zh", ""),
                                    language="markdown",
                                )
                                st.markdown("---")

        except Exception as e:
            st.error(f"ä¸‹è½½æˆ–è§£æè§†é¢‘æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
